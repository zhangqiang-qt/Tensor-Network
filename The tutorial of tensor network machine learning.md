## 简介

本教程的目标是介绍张量网络的基础，并对最近的张量网络应用到机器学习上取得的效果进行一个综述。

## 张量网络表示数据

卷积神经网络中的特征映射、视频、核磁共振成像、脑电图、高光谱影像和医疗知识图谱等数据都具备多维的结构。

![image](https://user-images.githubusercontent.com/33458582/109579197-6439f300-7b33-11eb-862c-d281678d4f91.png)

张量是向量和矩阵的泛化，可以很好地表示上述的多维数据。下图展示了一个三阶张量，以及对该张量的按不同维度(或模)的切片和纤维操作。

![image](https://user-images.githubusercontent.com/33458582/109579371-bbd85e80-7b33-11eb-91a2-9bedb28f2111.png)

直接对张量进行处理和操作是非常不和谐的，因为随着数据的增多，复杂度呈指数增长。由于数据中存在大量的冗余数据，因此，考虑对张量进行分解，以得到更小的、包含绝大部分有效信息的核张量。

#### 常用的张量分解方法包括：

1) Tucker分解，也称高阶奇异值分解(HOSVD)：将一个大张量分解为一个核张量与多个因子矩阵相乘的形式。

2) CP分解：将一个大张量分解为多个秩一张量的和的形式。

多线性维度裁剪：

* SVD、PCA和ICA的多线性扩展

张量盲源分离：应用于多种潜在因素。

#### 张量分解的有效学习算法

对于非监督学习来说，包括矩估计、通过高阶矩估计学习和张量幂分解。

#### 机器学习中的缺失值问题
在推荐系统、知识图谱预测、图像修复/降噪和药物重定位中，存在缺失值问题。也就是说，此时的数据形成的张量不是一个完整的张量，因此需要将其修复为完整的张量。

#### 张量增补
方法：凸优化低秩近似(计算代价高)、基于分解的方法(秩选择问题)、凸优化和分解方法的结合、整合先验知识。

学习最优张量秩：张量分解的概率模型、因子矩阵上的群稀疏性先验、模型参数后验的贝叶斯推断。




